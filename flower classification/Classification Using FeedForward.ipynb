{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     species  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "145        2  \n",
       "146        2  \n",
       "147        2  \n",
       "148        2  \n",
       "149        2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "x , y = iris.data , iris.target \n",
    " \n",
    "# To Visualize in Dataframe\n",
    "df = pd.DataFrame(x,columns=iris.feature_names)  # VARIABLE INDEPENDENT\n",
    "df['species'] = y   # VARIABLE DEPENDENT\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "species              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()  # CHECK IF THERE'S NULL VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA INTO DATA TRAINING AND DATA TESTING\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=12,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (120,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │            \u001b[38;5;34m75\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m30\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249</span> (996.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m249\u001b[0m (996.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249</span> (996.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m249\u001b[0m (996.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CREATE FEED FORWARD ARCHITECTURE\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(4,)),\n",
    "    keras.layers.Dense(units=15,activation='relu',use_bias=True),\n",
    "    keras.layers.Dense(units=9,activation='relu',use_bias=True),\n",
    "    keras.layers.Dense(units=3,activation='softmax',use_bias=True)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEASURE MODEL PERFORMANCE DURING TRAINING\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['Accuracy'],run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECLARING CALLBACKS WHEN FIT\n",
    "\n",
    "class mycallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs['loss'] < 0.06:\n",
    "            print('\\nModel Almost Perfect. Training Cancelled\\n')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - Accuracy: 0.3155 - loss: 1.9118 - val_Accuracy: 0.3000 - val_loss: 1.7270\n",
      "Epoch 2/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.3377 - loss: 1.5811 - val_Accuracy: 0.3000 - val_loss: 1.5271\n",
      "Epoch 3/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.3485 - loss: 1.3599 - val_Accuracy: 0.3000 - val_loss: 1.4084\n",
      "Epoch 4/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.2746 - loss: 1.3762 - val_Accuracy: 0.2333 - val_loss: 1.3480\n",
      "Epoch 5/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.1766 - loss: 1.2657 - val_Accuracy: 0.2333 - val_loss: 1.3089\n",
      "Epoch 6/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.1746 - loss: 1.2740 - val_Accuracy: 0.2667 - val_loss: 1.2687\n",
      "Epoch 7/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.1894 - loss: 1.2445 - val_Accuracy: 0.2333 - val_loss: 1.2295\n",
      "Epoch 8/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.1660 - loss: 1.1939 - val_Accuracy: 0.2667 - val_loss: 1.1979\n",
      "Epoch 9/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.2272 - loss: 1.1430 - val_Accuracy: 0.2667 - val_loss: 1.1708\n",
      "Epoch 10/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.2893 - loss: 1.1720 - val_Accuracy: 0.3000 - val_loss: 1.1475\n",
      "Epoch 11/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.2885 - loss: 1.1395 - val_Accuracy: 0.3000 - val_loss: 1.1255\n",
      "Epoch 12/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.3341 - loss: 1.1137 - val_Accuracy: 0.3000 - val_loss: 1.1059\n",
      "Epoch 13/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.3653 - loss: 1.0658 - val_Accuracy: 0.3000 - val_loss: 1.0881\n",
      "Epoch 14/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.2914 - loss: 1.0805 - val_Accuracy: 0.2667 - val_loss: 1.0711\n",
      "Epoch 15/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - Accuracy: 0.2909 - loss: 1.0431 - val_Accuracy: 0.3000 - val_loss: 1.0565\n",
      "Epoch 16/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.3410 - loss: 1.0229 - val_Accuracy: 0.3000 - val_loss: 1.0445\n",
      "Epoch 17/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.3244 - loss: 1.0178 - val_Accuracy: 0.3000 - val_loss: 1.0333\n",
      "Epoch 18/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - Accuracy: 0.3280 - loss: 1.0108 - val_Accuracy: 0.3000 - val_loss: 1.0228\n",
      "Epoch 19/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - Accuracy: 0.3032 - loss: 0.9958 - val_Accuracy: 0.3667 - val_loss: 1.0128\n",
      "Epoch 20/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.2758 - loss: 1.0015 - val_Accuracy: 0.3667 - val_loss: 1.0029\n",
      "Epoch 21/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.2889 - loss: 0.9963 - val_Accuracy: 0.3333 - val_loss: 0.9934\n",
      "Epoch 22/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - Accuracy: 0.2790 - loss: 0.9957 - val_Accuracy: 0.3000 - val_loss: 0.9842\n",
      "Epoch 23/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.3395 - loss: 0.9600 - val_Accuracy: 0.3667 - val_loss: 0.9753\n",
      "Epoch 24/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.3590 - loss: 0.9549 - val_Accuracy: 0.3667 - val_loss: 0.9659\n",
      "Epoch 25/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.3109 - loss: 0.9696 - val_Accuracy: 0.3667 - val_loss: 0.9563\n",
      "Epoch 26/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.3645 - loss: 0.9116 - val_Accuracy: 0.3000 - val_loss: 0.9479\n",
      "Epoch 27/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.3243 - loss: 0.9366 - val_Accuracy: 0.3333 - val_loss: 0.9382\n",
      "Epoch 28/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.3435 - loss: 0.9185 - val_Accuracy: 0.3333 - val_loss: 0.9285\n",
      "Epoch 29/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.3544 - loss: 0.9173 - val_Accuracy: 0.4333 - val_loss: 0.9187\n",
      "Epoch 30/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.4708 - loss: 0.8775 - val_Accuracy: 0.4000 - val_loss: 0.9094\n",
      "Epoch 31/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.4699 - loss: 0.8791 - val_Accuracy: 0.5000 - val_loss: 0.8994\n",
      "Epoch 32/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - Accuracy: 0.5265 - loss: 0.8756 - val_Accuracy: 0.5667 - val_loss: 0.8890\n",
      "Epoch 33/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.6094 - loss: 0.8570 - val_Accuracy: 0.5667 - val_loss: 0.8793\n",
      "Epoch 34/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.6227 - loss: 0.8559 - val_Accuracy: 0.6667 - val_loss: 0.8695\n",
      "Epoch 35/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.6628 - loss: 0.8350 - val_Accuracy: 0.6333 - val_loss: 0.8604\n",
      "Epoch 36/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.6634 - loss: 0.8398 - val_Accuracy: 0.7000 - val_loss: 0.8516\n",
      "Epoch 37/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.7065 - loss: 0.8147 - val_Accuracy: 0.6667 - val_loss: 0.8439\n",
      "Epoch 38/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.7356 - loss: 0.8376 - val_Accuracy: 0.7333 - val_loss: 0.8361\n",
      "Epoch 39/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.7926 - loss: 0.8209 - val_Accuracy: 0.6667 - val_loss: 0.8283\n",
      "Epoch 40/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.7224 - loss: 0.8053 - val_Accuracy: 0.7000 - val_loss: 0.8218\n",
      "Epoch 41/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.7419 - loss: 0.7947 - val_Accuracy: 0.7000 - val_loss: 0.8154\n",
      "Epoch 42/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.7523 - loss: 0.7951 - val_Accuracy: 0.7333 - val_loss: 0.8089\n",
      "Epoch 43/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.7379 - loss: 0.7704 - val_Accuracy: 0.7333 - val_loss: 0.8029\n",
      "Epoch 44/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.7572 - loss: 0.7653 - val_Accuracy: 0.7333 - val_loss: 0.7966\n",
      "Epoch 45/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.8048 - loss: 0.7703 - val_Accuracy: 0.9000 - val_loss: 0.7911\n",
      "Epoch 46/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9077 - loss: 0.7735 - val_Accuracy: 0.9000 - val_loss: 0.7834\n",
      "Epoch 47/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9099 - loss: 0.7556 - val_Accuracy: 0.7667 - val_loss: 0.7771\n",
      "Epoch 48/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.8251 - loss: 0.7751 - val_Accuracy: 0.7667 - val_loss: 0.7714\n",
      "Epoch 49/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.7793 - loss: 0.7413 - val_Accuracy: 0.7667 - val_loss: 0.7668\n",
      "Epoch 50/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.7879 - loss: 0.7385 - val_Accuracy: 0.7667 - val_loss: 0.7619\n",
      "Epoch 51/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.8443 - loss: 0.7550 - val_Accuracy: 0.8667 - val_loss: 0.7563\n",
      "Epoch 52/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9005 - loss: 0.7238 - val_Accuracy: 0.8333 - val_loss: 0.7520\n",
      "Epoch 53/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.8748 - loss: 0.7204 - val_Accuracy: 0.8333 - val_loss: 0.7468\n",
      "Epoch 54/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.8986 - loss: 0.7127 - val_Accuracy: 0.9000 - val_loss: 0.7418\n",
      "Epoch 55/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9357 - loss: 0.7156 - val_Accuracy: 0.9000 - val_loss: 0.7365\n",
      "Epoch 56/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9134 - loss: 0.7137 - val_Accuracy: 0.9000 - val_loss: 0.7313\n",
      "Epoch 57/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9116 - loss: 0.6945 - val_Accuracy: 0.8667 - val_loss: 0.7269\n",
      "Epoch 58/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9031 - loss: 0.6819 - val_Accuracy: 0.8333 - val_loss: 0.7228\n",
      "Epoch 59/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.8780 - loss: 0.6929 - val_Accuracy: 0.8667 - val_loss: 0.7178\n",
      "Epoch 60/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.8901 - loss: 0.6986 - val_Accuracy: 0.9333 - val_loss: 0.7116\n",
      "Epoch 61/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9380 - loss: 0.6798 - val_Accuracy: 0.9000 - val_loss: 0.6998\n",
      "Epoch 62/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9413 - loss: 0.6773 - val_Accuracy: 0.8333 - val_loss: 0.6923\n",
      "Epoch 63/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.8838 - loss: 0.6787 - val_Accuracy: 0.8333 - val_loss: 0.6858\n",
      "Epoch 64/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9212 - loss: 0.6570 - val_Accuracy: 0.9333 - val_loss: 0.6776\n",
      "Epoch 65/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9693 - loss: 0.6391 - val_Accuracy: 0.9333 - val_loss: 0.6698\n",
      "Epoch 66/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.9575 - loss: 0.6407 - val_Accuracy: 0.9333 - val_loss: 0.6625\n",
      "Epoch 67/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9362 - loss: 0.6336 - val_Accuracy: 0.9333 - val_loss: 0.6574\n",
      "Epoch 68/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9586 - loss: 0.6243 - val_Accuracy: 0.9333 - val_loss: 0.6516\n",
      "Epoch 69/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9589 - loss: 0.6080 - val_Accuracy: 0.9333 - val_loss: 0.6443\n",
      "Epoch 70/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9419 - loss: 0.5957 - val_Accuracy: 0.9333 - val_loss: 0.6370\n",
      "Epoch 71/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9353 - loss: 0.5993 - val_Accuracy: 0.9333 - val_loss: 0.6309\n",
      "Epoch 72/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9249 - loss: 0.6001 - val_Accuracy: 0.9333 - val_loss: 0.6247\n",
      "Epoch 73/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9646 - loss: 0.5894 - val_Accuracy: 0.9333 - val_loss: 0.6212\n",
      "Epoch 74/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9645 - loss: 0.5794 - val_Accuracy: 0.9333 - val_loss: 0.6137\n",
      "Epoch 75/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9657 - loss: 0.5646 - val_Accuracy: 0.9333 - val_loss: 0.6064\n",
      "Epoch 76/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9432 - loss: 0.5550 - val_Accuracy: 0.9333 - val_loss: 0.6028\n",
      "Epoch 77/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9734 - loss: 0.5592 - val_Accuracy: 0.9333 - val_loss: 0.5961\n",
      "Epoch 78/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9375 - loss: 0.5581 - val_Accuracy: 0.9333 - val_loss: 0.5899\n",
      "Epoch 79/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9497 - loss: 0.5607 - val_Accuracy: 0.9333 - val_loss: 0.5845\n",
      "Epoch 80/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9702 - loss: 0.5613 - val_Accuracy: 0.9333 - val_loss: 0.5816\n",
      "Epoch 81/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9598 - loss: 0.5389 - val_Accuracy: 0.9333 - val_loss: 0.5770\n",
      "Epoch 82/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9523 - loss: 0.5392 - val_Accuracy: 0.9333 - val_loss: 0.5694\n",
      "Epoch 83/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9462 - loss: 0.5162 - val_Accuracy: 0.9333 - val_loss: 0.5668\n",
      "Epoch 84/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9605 - loss: 0.5214 - val_Accuracy: 0.9667 - val_loss: 0.5590\n",
      "Epoch 85/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9575 - loss: 0.5176 - val_Accuracy: 0.9333 - val_loss: 0.5546\n",
      "Epoch 86/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9441 - loss: 0.5236 - val_Accuracy: 0.9333 - val_loss: 0.5497\n",
      "Epoch 87/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9528 - loss: 0.5171 - val_Accuracy: 0.9333 - val_loss: 0.5479\n",
      "Epoch 88/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9523 - loss: 0.5033 - val_Accuracy: 0.9333 - val_loss: 0.5420\n",
      "Epoch 89/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9625 - loss: 0.4982 - val_Accuracy: 1.0000 - val_loss: 0.5361\n",
      "Epoch 90/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9702 - loss: 0.4957 - val_Accuracy: 0.9333 - val_loss: 0.5329\n",
      "Epoch 91/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9614 - loss: 0.5067 - val_Accuracy: 0.9333 - val_loss: 0.5289\n",
      "Epoch 92/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.9681 - loss: 0.4759 - val_Accuracy: 0.9333 - val_loss: 0.5282\n",
      "Epoch 93/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9637 - loss: 0.4740 - val_Accuracy: 0.9333 - val_loss: 0.5198\n",
      "Epoch 94/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9623 - loss: 0.4707 - val_Accuracy: 1.0000 - val_loss: 0.5137\n",
      "Epoch 95/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9497 - loss: 0.4772 - val_Accuracy: 0.9667 - val_loss: 0.5102\n",
      "Epoch 96/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - Accuracy: 0.9693 - loss: 0.4748 - val_Accuracy: 0.9333 - val_loss: 0.5106\n",
      "Epoch 97/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9588 - loss: 0.4726 - val_Accuracy: 0.9667 - val_loss: 0.5016\n",
      "Epoch 98/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9641 - loss: 0.4597 - val_Accuracy: 0.9667 - val_loss: 0.4979\n",
      "Epoch 99/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9762 - loss: 0.4560 - val_Accuracy: 0.9333 - val_loss: 0.4970\n",
      "Epoch 100/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9460 - loss: 0.4631 - val_Accuracy: 0.9667 - val_loss: 0.4895\n",
      "Epoch 101/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9719 - loss: 0.4277 - val_Accuracy: 0.9667 - val_loss: 0.4857\n",
      "Epoch 102/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9497 - loss: 0.4444 - val_Accuracy: 0.9333 - val_loss: 0.4840\n",
      "Epoch 103/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9467 - loss: 0.4412 - val_Accuracy: 0.9333 - val_loss: 0.4806\n",
      "Epoch 104/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9532 - loss: 0.4413 - val_Accuracy: 0.9667 - val_loss: 0.4749\n",
      "Epoch 105/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9653 - loss: 0.4384 - val_Accuracy: 0.9667 - val_loss: 0.4715\n",
      "Epoch 106/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9645 - loss: 0.4250 - val_Accuracy: 0.9667 - val_loss: 0.4674\n",
      "Epoch 107/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9450 - loss: 0.4273 - val_Accuracy: 0.9667 - val_loss: 0.4645\n",
      "Epoch 108/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9602 - loss: 0.4066 - val_Accuracy: 0.9667 - val_loss: 0.4596\n",
      "Epoch 109/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9780 - loss: 0.4136 - val_Accuracy: 0.9667 - val_loss: 0.4570\n",
      "Epoch 110/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9668 - loss: 0.3894 - val_Accuracy: 1.0000 - val_loss: 0.4523\n",
      "Epoch 111/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9611 - loss: 0.4133 - val_Accuracy: 0.9667 - val_loss: 0.4495\n",
      "Epoch 112/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9645 - loss: 0.3969 - val_Accuracy: 0.9667 - val_loss: 0.4473\n",
      "Epoch 113/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9606 - loss: 0.3801 - val_Accuracy: 0.9333 - val_loss: 0.4458\n",
      "Epoch 114/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9503 - loss: 0.4015 - val_Accuracy: 1.0000 - val_loss: 0.4375\n",
      "Epoch 115/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9658 - loss: 0.3913 - val_Accuracy: 0.9667 - val_loss: 0.4354\n",
      "Epoch 116/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9589 - loss: 0.3781 - val_Accuracy: 0.9667 - val_loss: 0.4322\n",
      "Epoch 117/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9676 - loss: 0.3782 - val_Accuracy: 0.9667 - val_loss: 0.4314\n",
      "Epoch 118/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9585 - loss: 0.3703 - val_Accuracy: 0.9667 - val_loss: 0.4285\n",
      "Epoch 119/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9450 - loss: 0.3949 - val_Accuracy: 1.0000 - val_loss: 0.4217\n",
      "Epoch 120/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9585 - loss: 0.3750 - val_Accuracy: 0.9667 - val_loss: 0.4209\n",
      "Epoch 121/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9563 - loss: 0.3872 - val_Accuracy: 0.9667 - val_loss: 0.4174\n",
      "Epoch 122/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.9789 - loss: 0.3672 - val_Accuracy: 1.0000 - val_loss: 0.4134\n",
      "Epoch 123/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9502 - loss: 0.3701 - val_Accuracy: 0.9667 - val_loss: 0.4124\n",
      "Epoch 124/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9593 - loss: 0.3667 - val_Accuracy: 0.9667 - val_loss: 0.4087\n",
      "Epoch 125/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9728 - loss: 0.3630 - val_Accuracy: 1.0000 - val_loss: 0.4044\n",
      "Epoch 126/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9684 - loss: 0.3696 - val_Accuracy: 0.9667 - val_loss: 0.4038\n",
      "Epoch 127/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9580 - loss: 0.3585 - val_Accuracy: 1.0000 - val_loss: 0.3989\n",
      "Epoch 128/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9493 - loss: 0.3632 - val_Accuracy: 0.9667 - val_loss: 0.3993\n",
      "Epoch 129/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9611 - loss: 0.3362 - val_Accuracy: 0.9667 - val_loss: 0.3954\n",
      "Epoch 130/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9694 - loss: 0.3639 - val_Accuracy: 1.0000 - val_loss: 0.3910\n",
      "Epoch 131/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9655 - loss: 0.3474 - val_Accuracy: 1.0000 - val_loss: 0.3887\n",
      "Epoch 132/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9824 - loss: 0.3275 - val_Accuracy: 0.9667 - val_loss: 0.3875\n",
      "Epoch 133/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9611 - loss: 0.3637 - val_Accuracy: 1.0000 - val_loss: 0.3828\n",
      "Epoch 134/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9589 - loss: 0.3623 - val_Accuracy: 0.9667 - val_loss: 0.3807\n",
      "Epoch 135/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - Accuracy: 0.9619 - loss: 0.3363 - val_Accuracy: 0.9667 - val_loss: 0.3818\n",
      "Epoch 136/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9628 - loss: 0.3417 - val_Accuracy: 0.9667 - val_loss: 0.3771\n",
      "Epoch 137/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9585 - loss: 0.3445 - val_Accuracy: 1.0000 - val_loss: 0.3717\n",
      "Epoch 138/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9686 - loss: 0.3323 - val_Accuracy: 1.0000 - val_loss: 0.3708\n",
      "Epoch 139/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9671 - loss: 0.3170 - val_Accuracy: 0.9667 - val_loss: 0.3694\n",
      "Epoch 140/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9511 - loss: 0.3464 - val_Accuracy: 1.0000 - val_loss: 0.3647\n",
      "Epoch 141/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9655 - loss: 0.3248 - val_Accuracy: 1.0000 - val_loss: 0.3630\n",
      "Epoch 142/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9676 - loss: 0.3278 - val_Accuracy: 0.9667 - val_loss: 0.3632\n",
      "Epoch 143/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9650 - loss: 0.3138 - val_Accuracy: 1.0000 - val_loss: 0.3564\n",
      "Epoch 144/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9602 - loss: 0.3140 - val_Accuracy: 0.9667 - val_loss: 0.3572\n",
      "Epoch 145/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - Accuracy: 0.9728 - loss: 0.3294 - val_Accuracy: 0.9667 - val_loss: 0.3558\n",
      "Epoch 146/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.9710 - loss: 0.3200 - val_Accuracy: 1.0000 - val_loss: 0.3500\n",
      "Epoch 147/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9555 - loss: 0.3253 - val_Accuracy: 0.9667 - val_loss: 0.3498\n",
      "Epoch 148/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9762 - loss: 0.3040 - val_Accuracy: 0.9667 - val_loss: 0.3500\n",
      "Epoch 149/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9503 - loss: 0.2956 - val_Accuracy: 1.0000 - val_loss: 0.3430\n",
      "Epoch 150/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9641 - loss: 0.3158 - val_Accuracy: 1.0000 - val_loss: 0.3408\n",
      "Epoch 151/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9559 - loss: 0.3179 - val_Accuracy: 0.9667 - val_loss: 0.3412\n",
      "Epoch 152/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9440 - loss: 0.3116 - val_Accuracy: 0.9667 - val_loss: 0.3395\n",
      "Epoch 153/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9480 - loss: 0.3145 - val_Accuracy: 0.9667 - val_loss: 0.3395\n",
      "Epoch 154/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9485 - loss: 0.3168 - val_Accuracy: 0.9667 - val_loss: 0.3374\n",
      "Epoch 155/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9711 - loss: 0.2710 - val_Accuracy: 1.0000 - val_loss: 0.3301\n",
      "Epoch 156/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9637 - loss: 0.2759 - val_Accuracy: 1.0000 - val_loss: 0.3279\n",
      "Epoch 157/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9702 - loss: 0.2968 - val_Accuracy: 0.9667 - val_loss: 0.3294\n",
      "Epoch 158/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9493 - loss: 0.2838 - val_Accuracy: 0.9667 - val_loss: 0.3286\n",
      "Epoch 159/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9550 - loss: 0.2678 - val_Accuracy: 0.9667 - val_loss: 0.3249\n",
      "Epoch 160/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - Accuracy: 0.9793 - loss: 0.2729 - val_Accuracy: 0.9667 - val_loss: 0.3229\n",
      "Epoch 161/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9711 - loss: 0.2827 - val_Accuracy: 1.0000 - val_loss: 0.3190\n",
      "Epoch 162/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9759 - loss: 0.2839 - val_Accuracy: 0.9667 - val_loss: 0.3188\n",
      "Epoch 163/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9602 - loss: 0.2760 - val_Accuracy: 0.9667 - val_loss: 0.3164\n",
      "Epoch 164/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9710 - loss: 0.2773 - val_Accuracy: 0.9667 - val_loss: 0.3146\n",
      "Epoch 165/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9697 - loss: 0.2700 - val_Accuracy: 0.9667 - val_loss: 0.3129\n",
      "Epoch 166/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9611 - loss: 0.2662 - val_Accuracy: 0.9667 - val_loss: 0.3113\n",
      "Epoch 167/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9702 - loss: 0.2704 - val_Accuracy: 0.9667 - val_loss: 0.3092\n",
      "Epoch 168/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9589 - loss: 0.2671 - val_Accuracy: 1.0000 - val_loss: 0.3063\n",
      "Epoch 169/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9702 - loss: 0.2761 - val_Accuracy: 1.0000 - val_loss: 0.3035\n",
      "Epoch 170/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9633 - loss: 0.2569 - val_Accuracy: 0.9667 - val_loss: 0.3039\n",
      "Epoch 171/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9671 - loss: 0.2657 - val_Accuracy: 0.9667 - val_loss: 0.3037\n",
      "Epoch 172/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9641 - loss: 0.2734 - val_Accuracy: 1.0000 - val_loss: 0.2972\n",
      "Epoch 173/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9707 - loss: 0.2493 - val_Accuracy: 1.0000 - val_loss: 0.2954\n",
      "Epoch 174/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9676 - loss: 0.2643 - val_Accuracy: 1.0000 - val_loss: 0.2959\n",
      "Epoch 175/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9431 - loss: 0.2748 - val_Accuracy: 0.9667 - val_loss: 0.2986\n",
      "Epoch 176/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9580 - loss: 0.2539 - val_Accuracy: 0.9667 - val_loss: 0.2959\n",
      "Epoch 177/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9641 - loss: 0.2423 - val_Accuracy: 1.0000 - val_loss: 0.2907\n",
      "Epoch 178/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9832 - loss: 0.2462 - val_Accuracy: 1.0000 - val_loss: 0.2861\n",
      "Epoch 179/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9785 - loss: 0.2425 - val_Accuracy: 1.0000 - val_loss: 0.2872\n",
      "Epoch 180/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9485 - loss: 0.2732 - val_Accuracy: 0.9667 - val_loss: 0.2876\n",
      "Epoch 181/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9607 - loss: 0.2516 - val_Accuracy: 0.9667 - val_loss: 0.2862\n",
      "Epoch 182/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9598 - loss: 0.2493 - val_Accuracy: 1.0000 - val_loss: 0.2810\n",
      "Epoch 183/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9764 - loss: 0.2546 - val_Accuracy: 1.0000 - val_loss: 0.2788\n",
      "Epoch 184/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9650 - loss: 0.2643 - val_Accuracy: 1.0000 - val_loss: 0.2791\n",
      "Epoch 185/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9632 - loss: 0.2495 - val_Accuracy: 0.9667 - val_loss: 0.2795\n",
      "Epoch 186/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9524 - loss: 0.2563 - val_Accuracy: 0.9667 - val_loss: 0.2789\n",
      "Epoch 187/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9746 - loss: 0.2557 - val_Accuracy: 1.0000 - val_loss: 0.2738\n",
      "Epoch 188/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9737 - loss: 0.2301 - val_Accuracy: 0.9667 - val_loss: 0.2733\n",
      "Epoch 189/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9615 - loss: 0.2391 - val_Accuracy: 1.0000 - val_loss: 0.2705\n",
      "Epoch 190/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9663 - loss: 0.2466 - val_Accuracy: 0.9667 - val_loss: 0.2711\n",
      "Epoch 191/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9668 - loss: 0.2465 - val_Accuracy: 0.9667 - val_loss: 0.2779\n",
      "Epoch 192/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9684 - loss: 0.2348 - val_Accuracy: 0.9667 - val_loss: 0.2686\n",
      "Epoch 193/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9733 - loss: 0.2173 - val_Accuracy: 1.0000 - val_loss: 0.2634\n",
      "Epoch 194/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9785 - loss: 0.2345 - val_Accuracy: 1.0000 - val_loss: 0.2611\n",
      "Epoch 195/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9628 - loss: 0.2412 - val_Accuracy: 0.9667 - val_loss: 0.2684\n",
      "Epoch 196/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9689 - loss: 0.2230 - val_Accuracy: 0.9667 - val_loss: 0.2636\n",
      "Epoch 197/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9572 - loss: 0.2175 - val_Accuracy: 1.0000 - val_loss: 0.2584\n",
      "Epoch 198/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9772 - loss: 0.2374 - val_Accuracy: 1.0000 - val_loss: 0.2559\n",
      "Epoch 199/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9802 - loss: 0.2249 - val_Accuracy: 0.9667 - val_loss: 0.2617\n",
      "Epoch 200/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9628 - loss: 0.2375 - val_Accuracy: 0.9667 - val_loss: 0.2613\n",
      "Epoch 201/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9697 - loss: 0.2151 - val_Accuracy: 1.0000 - val_loss: 0.2545\n",
      "Epoch 202/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9598 - loss: 0.2314 - val_Accuracy: 1.0000 - val_loss: 0.2513\n",
      "Epoch 203/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9602 - loss: 0.2515 - val_Accuracy: 0.9667 - val_loss: 0.2522\n",
      "Epoch 204/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9697 - loss: 0.2136 - val_Accuracy: 0.9667 - val_loss: 0.2518\n",
      "Epoch 205/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - Accuracy: 0.9645 - loss: 0.2054 - val_Accuracy: 1.0000 - val_loss: 0.2480\n",
      "Epoch 206/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9477 - loss: 0.2299 - val_Accuracy: 0.9667 - val_loss: 0.2483\n",
      "Epoch 207/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9554 - loss: 0.2273 - val_Accuracy: 0.9667 - val_loss: 0.2490\n",
      "Epoch 208/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9602 - loss: 0.2258 - val_Accuracy: 0.9667 - val_loss: 0.2493\n",
      "Epoch 209/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9598 - loss: 0.2145 - val_Accuracy: 1.0000 - val_loss: 0.2429\n",
      "Epoch 210/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9681 - loss: 0.2100 - val_Accuracy: 1.0000 - val_loss: 0.2407\n",
      "Epoch 211/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9507 - loss: 0.2421 - val_Accuracy: 0.9667 - val_loss: 0.2431\n",
      "Epoch 212/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - Accuracy: 0.9372 - loss: 0.2279 - val_Accuracy: 0.9667 - val_loss: 0.2462\n",
      "Epoch 213/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9776 - loss: 0.2203 - val_Accuracy: 0.9667 - val_loss: 0.2433\n",
      "Epoch 214/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9701 - loss: 0.2103 - val_Accuracy: 1.0000 - val_loss: 0.2367\n",
      "Epoch 215/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9868 - loss: 0.2054 - val_Accuracy: 1.0000 - val_loss: 0.2341\n",
      "Epoch 216/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9872 - loss: 0.2078 - val_Accuracy: 1.0000 - val_loss: 0.2347\n",
      "Epoch 217/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9537 - loss: 0.2297 - val_Accuracy: 0.9667 - val_loss: 0.2394\n",
      "Epoch 218/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9655 - loss: 0.2068 - val_Accuracy: 0.9667 - val_loss: 0.2380\n",
      "Epoch 219/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9706 - loss: 0.2012 - val_Accuracy: 1.0000 - val_loss: 0.2307\n",
      "Epoch 220/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9750 - loss: 0.2021 - val_Accuracy: 1.0000 - val_loss: 0.2303\n",
      "Epoch 221/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.9777 - loss: 0.2040 - val_Accuracy: 1.0000 - val_loss: 0.2266\n",
      "Epoch 222/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - Accuracy: 0.9733 - loss: 0.1981 - val_Accuracy: 0.9667 - val_loss: 0.2304\n",
      "Epoch 223/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - Accuracy: 0.9519 - loss: 0.2137 - val_Accuracy: 0.9667 - val_loss: 0.2301\n",
      "Epoch 224/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9710 - loss: 0.1892 - val_Accuracy: 1.0000 - val_loss: 0.2263\n",
      "Epoch 225/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9641 - loss: 0.2017 - val_Accuracy: 0.9667 - val_loss: 0.2303\n",
      "Epoch 226/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9736 - loss: 0.1869 - val_Accuracy: 1.0000 - val_loss: 0.2220\n",
      "Epoch 227/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9615 - loss: 0.2087 - val_Accuracy: 1.0000 - val_loss: 0.2230\n",
      "Epoch 228/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9674 - loss: 0.1877 - val_Accuracy: 0.9667 - val_loss: 0.2237\n",
      "Epoch 229/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.9554 - loss: 0.2187 - val_Accuracy: 0.9667 - val_loss: 0.2245\n",
      "Epoch 230/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9684 - loss: 0.1901 - val_Accuracy: 0.9667 - val_loss: 0.2219\n",
      "Epoch 231/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9537 - loss: 0.2115 - val_Accuracy: 1.0000 - val_loss: 0.2163\n",
      "Epoch 232/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9716 - loss: 0.2054 - val_Accuracy: 1.0000 - val_loss: 0.2150\n",
      "Epoch 233/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9724 - loss: 0.1844 - val_Accuracy: 0.9667 - val_loss: 0.2230\n",
      "Epoch 234/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9737 - loss: 0.1990 - val_Accuracy: 0.9667 - val_loss: 0.2231\n",
      "Epoch 235/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9768 - loss: 0.2034 - val_Accuracy: 1.0000 - val_loss: 0.2116\n",
      "Epoch 236/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9638 - loss: 0.2128 - val_Accuracy: 1.0000 - val_loss: 0.2108\n",
      "Epoch 237/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9737 - loss: 0.2010 - val_Accuracy: 1.0000 - val_loss: 0.2106\n",
      "Epoch 238/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9784 - loss: 0.1779 - val_Accuracy: 0.9667 - val_loss: 0.2194\n",
      "Epoch 239/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9689 - loss: 0.1982 - val_Accuracy: 1.0000 - val_loss: 0.2106\n",
      "Epoch 240/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9798 - loss: 0.1853 - val_Accuracy: 1.0000 - val_loss: 0.2064\n",
      "Epoch 241/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9755 - loss: 0.1838 - val_Accuracy: 1.0000 - val_loss: 0.2089\n",
      "Epoch 242/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9607 - loss: 0.2026 - val_Accuracy: 0.9667 - val_loss: 0.2100\n",
      "Epoch 243/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9611 - loss: 0.1964 - val_Accuracy: 0.9667 - val_loss: 0.2112\n",
      "Epoch 244/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9780 - loss: 0.1909 - val_Accuracy: 0.9667 - val_loss: 0.2064\n",
      "Epoch 245/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9755 - loss: 0.1732 - val_Accuracy: 1.0000 - val_loss: 0.2025\n",
      "Epoch 246/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9881 - loss: 0.1749 - val_Accuracy: 1.0000 - val_loss: 0.2012\n",
      "Epoch 247/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9885 - loss: 0.1661 - val_Accuracy: 1.0000 - val_loss: 0.2003\n",
      "Epoch 248/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9650 - loss: 0.1872 - val_Accuracy: 0.9667 - val_loss: 0.2044\n",
      "Epoch 249/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9589 - loss: 0.1830 - val_Accuracy: 0.9667 - val_loss: 0.2046\n",
      "Epoch 250/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9781 - loss: 0.1714 - val_Accuracy: 1.0000 - val_loss: 0.1980\n",
      "Epoch 251/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9868 - loss: 0.1694 - val_Accuracy: 1.0000 - val_loss: 0.1963\n",
      "Epoch 252/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9811 - loss: 0.1686 - val_Accuracy: 1.0000 - val_loss: 0.1933\n",
      "Epoch 253/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9625 - loss: 0.1908 - val_Accuracy: 1.0000 - val_loss: 0.1968\n",
      "Epoch 254/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9668 - loss: 0.1771 - val_Accuracy: 1.0000 - val_loss: 0.1971\n",
      "Epoch 255/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9872 - loss: 0.1521 - val_Accuracy: 1.0000 - val_loss: 0.1916\n",
      "Epoch 256/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9651 - loss: 0.1861 - val_Accuracy: 1.0000 - val_loss: 0.1910\n",
      "Epoch 257/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9742 - loss: 0.1649 - val_Accuracy: 1.0000 - val_loss: 0.1933\n",
      "Epoch 258/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9698 - loss: 0.1782 - val_Accuracy: 1.0000 - val_loss: 0.1920\n",
      "Epoch 259/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9581 - loss: 0.1746 - val_Accuracy: 1.0000 - val_loss: 0.1875\n",
      "Epoch 260/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9755 - loss: 0.1637 - val_Accuracy: 1.0000 - val_loss: 0.1856\n",
      "Epoch 261/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9737 - loss: 0.1816 - val_Accuracy: 1.0000 - val_loss: 0.1856\n",
      "Epoch 262/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9868 - loss: 0.1626 - val_Accuracy: 1.0000 - val_loss: 0.1878\n",
      "Epoch 263/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9651 - loss: 0.1862 - val_Accuracy: 0.9667 - val_loss: 0.1896\n",
      "Epoch 264/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9681 - loss: 0.1658 - val_Accuracy: 1.0000 - val_loss: 0.1853\n",
      "Epoch 265/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9711 - loss: 0.1710 - val_Accuracy: 1.0000 - val_loss: 0.1809\n",
      "Epoch 266/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9768 - loss: 0.1704 - val_Accuracy: 1.0000 - val_loss: 0.1803\n",
      "Epoch 267/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9668 - loss: 0.1918 - val_Accuracy: 1.0000 - val_loss: 0.1826\n",
      "Epoch 268/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9746 - loss: 0.1644 - val_Accuracy: 0.9667 - val_loss: 0.1857\n",
      "Epoch 269/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9724 - loss: 0.1642 - val_Accuracy: 1.0000 - val_loss: 0.1773\n",
      "Epoch 270/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9716 - loss: 0.1597 - val_Accuracy: 1.0000 - val_loss: 0.1834\n",
      "Epoch 271/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9677 - loss: 0.1718 - val_Accuracy: 1.0000 - val_loss: 0.1819\n",
      "Epoch 272/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9668 - loss: 0.1727 - val_Accuracy: 1.0000 - val_loss: 0.1766\n",
      "Epoch 273/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9842 - loss: 0.1456 - val_Accuracy: 1.0000 - val_loss: 0.1737\n",
      "Epoch 274/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9729 - loss: 0.1471 - val_Accuracy: 1.0000 - val_loss: 0.1776\n",
      "Epoch 275/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - Accuracy: 0.9860 - loss: 0.1677 - val_Accuracy: 0.9667 - val_loss: 0.1834\n",
      "Epoch 276/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9703 - loss: 0.1669 - val_Accuracy: 1.0000 - val_loss: 0.1787\n",
      "Epoch 277/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9733 - loss: 0.1655 - val_Accuracy: 1.0000 - val_loss: 0.1715\n",
      "Epoch 278/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9794 - loss: 0.1515 - val_Accuracy: 1.0000 - val_loss: 0.1701\n",
      "Epoch 279/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9811 - loss: 0.1535 - val_Accuracy: 1.0000 - val_loss: 0.1728\n",
      "Epoch 280/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9703 - loss: 0.1499 - val_Accuracy: 1.0000 - val_loss: 0.1729\n",
      "Epoch 281/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9625 - loss: 0.1750 - val_Accuracy: 1.0000 - val_loss: 0.1675\n",
      "Epoch 282/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9811 - loss: 0.1469 - val_Accuracy: 1.0000 - val_loss: 0.1717\n",
      "Epoch 283/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9607 - loss: 0.1652 - val_Accuracy: 1.0000 - val_loss: 0.1689\n",
      "Epoch 284/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9785 - loss: 0.1516 - val_Accuracy: 1.0000 - val_loss: 0.1652\n",
      "Epoch 285/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9690 - loss: 0.1707 - val_Accuracy: 1.0000 - val_loss: 0.1718\n",
      "Epoch 286/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9729 - loss: 0.1506 - val_Accuracy: 0.9667 - val_loss: 0.1748\n",
      "Epoch 287/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9685 - loss: 0.1730 - val_Accuracy: 1.0000 - val_loss: 0.1679\n",
      "Epoch 288/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9614 - loss: 0.1630 - val_Accuracy: 1.0000 - val_loss: 0.1635\n",
      "Epoch 289/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9651 - loss: 0.1681 - val_Accuracy: 1.0000 - val_loss: 0.1644\n",
      "Epoch 290/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9837 - loss: 0.1369 - val_Accuracy: 1.0000 - val_loss: 0.1622\n",
      "Epoch 291/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9841 - loss: 0.1493 - val_Accuracy: 1.0000 - val_loss: 0.1604\n",
      "Epoch 292/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9685 - loss: 0.1570 - val_Accuracy: 1.0000 - val_loss: 0.1622\n",
      "Epoch 293/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9807 - loss: 0.1533 - val_Accuracy: 1.0000 - val_loss: 0.1644\n",
      "Epoch 294/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9807 - loss: 0.1455 - val_Accuracy: 1.0000 - val_loss: 0.1623\n",
      "Epoch 295/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9855 - loss: 0.1429 - val_Accuracy: 1.0000 - val_loss: 0.1596\n",
      "Epoch 296/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9772 - loss: 0.1334 - val_Accuracy: 1.0000 - val_loss: 0.1566\n",
      "Epoch 297/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9868 - loss: 0.1295 - val_Accuracy: 1.0000 - val_loss: 0.1575\n",
      "Epoch 298/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9759 - loss: 0.1522 - val_Accuracy: 1.0000 - val_loss: 0.1540\n",
      "Epoch 299/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9659 - loss: 0.1529 - val_Accuracy: 0.9667 - val_loss: 0.1646\n",
      "Epoch 300/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9625 - loss: 0.1587 - val_Accuracy: 0.9667 - val_loss: 0.1716\n",
      "Epoch 301/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9877 - loss: 0.1332 - val_Accuracy: 1.0000 - val_loss: 0.1592\n",
      "Epoch 302/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9774 - loss: 0.1468 - val_Accuracy: 1.0000 - val_loss: 0.1538\n",
      "Epoch 303/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9764 - loss: 0.1528 - val_Accuracy: 1.0000 - val_loss: 0.1532\n",
      "Epoch 304/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9757 - loss: 0.1425 - val_Accuracy: 1.0000 - val_loss: 0.1533\n",
      "Epoch 305/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9764 - loss: 0.1449 - val_Accuracy: 1.0000 - val_loss: 0.1526\n",
      "Epoch 306/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9824 - loss: 0.1352 - val_Accuracy: 1.0000 - val_loss: 0.1521\n",
      "Epoch 307/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9733 - loss: 0.1538 - val_Accuracy: 1.0000 - val_loss: 0.1526\n",
      "Epoch 308/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9772 - loss: 0.1443 - val_Accuracy: 1.0000 - val_loss: 0.1521\n",
      "Epoch 309/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9633 - loss: 0.1400 - val_Accuracy: 1.0000 - val_loss: 0.1533\n",
      "Epoch 310/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9877 - loss: 0.1443 - val_Accuracy: 1.0000 - val_loss: 0.1501\n",
      "Epoch 311/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9633 - loss: 0.1574 - val_Accuracy: 1.0000 - val_loss: 0.1504\n",
      "Epoch 312/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9633 - loss: 0.1465 - val_Accuracy: 1.0000 - val_loss: 0.1489\n",
      "Epoch 313/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9573 - loss: 0.1624 - val_Accuracy: 1.0000 - val_loss: 0.1475\n",
      "Epoch 314/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9659 - loss: 0.1540 - val_Accuracy: 1.0000 - val_loss: 0.1475\n",
      "Epoch 315/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9711 - loss: 0.1319 - val_Accuracy: 1.0000 - val_loss: 0.1487\n",
      "Epoch 316/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9581 - loss: 0.1576 - val_Accuracy: 1.0000 - val_loss: 0.1471\n",
      "Epoch 317/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9625 - loss: 0.1508 - val_Accuracy: 1.0000 - val_loss: 0.1463\n",
      "Epoch 318/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9877 - loss: 0.1272 - val_Accuracy: 1.0000 - val_loss: 0.1502\n",
      "Epoch 319/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9792 - loss: 0.1492 - val_Accuracy: 1.0000 - val_loss: 0.1425\n",
      "Epoch 320/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9668 - loss: 0.1423 - val_Accuracy: 1.0000 - val_loss: 0.1414\n",
      "Epoch 321/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9529 - loss: 0.1555 - val_Accuracy: 1.0000 - val_loss: 0.1446\n",
      "Epoch 322/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9716 - loss: 0.1354 - val_Accuracy: 1.0000 - val_loss: 0.1491\n",
      "Epoch 323/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9890 - loss: 0.1210 - val_Accuracy: 1.0000 - val_loss: 0.1416\n",
      "Epoch 324/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9868 - loss: 0.1180 - val_Accuracy: 1.0000 - val_loss: 0.1365\n",
      "Epoch 325/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9794 - loss: 0.1279 - val_Accuracy: 1.0000 - val_loss: 0.1326\n",
      "Epoch 326/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9812 - loss: 0.1225 - val_Accuracy: 1.0000 - val_loss: 0.1252\n",
      "Epoch 327/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9703 - loss: 0.1311 - val_Accuracy: 1.0000 - val_loss: 0.1103\n",
      "Epoch 328/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9811 - loss: 0.1006 - val_Accuracy: 1.0000 - val_loss: 0.0979\n",
      "Epoch 329/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9729 - loss: 0.1059 - val_Accuracy: 1.0000 - val_loss: 0.0818\n",
      "Epoch 330/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9796 - loss: 0.0733 - val_Accuracy: 1.0000 - val_loss: 0.0776\n",
      "Epoch 331/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.9851 - loss: 0.0722 - val_Accuracy: 1.0000 - val_loss: 0.0730\n",
      "Epoch 332/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - Accuracy: 0.9690 - loss: 0.0850 - val_Accuracy: 1.0000 - val_loss: 0.0641\n",
      "Epoch 333/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9737 - loss: 0.0629 - val_Accuracy: 1.0000 - val_loss: 0.0610\n",
      "Epoch 334/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9633 - loss: 0.0837 - val_Accuracy: 1.0000 - val_loss: 0.0614\n",
      "Epoch 335/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9837 - loss: 0.0594 - val_Accuracy: 1.0000 - val_loss: 0.0566\n",
      "Epoch 336/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9729 - loss: 0.0652 - val_Accuracy: 1.0000 - val_loss: 0.0600\n",
      "Epoch 337/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9729 - loss: 0.0763 - val_Accuracy: 1.0000 - val_loss: 0.0571\n",
      "Epoch 338/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9860 - loss: 0.0536 - val_Accuracy: 1.0000 - val_loss: 0.0577\n",
      "Epoch 339/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9772 - loss: 0.0619 - val_Accuracy: 1.0000 - val_loss: 0.0531\n",
      "Epoch 340/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - Accuracy: 0.9777 - loss: 0.0536 - val_Accuracy: 1.0000 - val_loss: 0.0590\n",
      "Epoch 341/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9847 - loss: 0.0611 - val_Accuracy: 1.0000 - val_loss: 0.0537\n",
      "Epoch 342/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - Accuracy: 0.9705 - loss: 0.0749 - val_Accuracy: 1.0000 - val_loss: 0.0515\n",
      "Epoch 343/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Accuracy: 0.9573 - loss: 0.0772 - val_Accuracy: 1.0000 - val_loss: 0.0554\n",
      "Epoch 344/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9781 - loss: 0.0538 - val_Accuracy: 1.0000 - val_loss: 0.0534\n",
      "Epoch 345/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Accuracy: 0.9824 - loss: 0.0498 - val_Accuracy: 1.0000 - val_loss: 0.0515\n",
      "Epoch 346/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9811 - loss: 0.0551 - val_Accuracy: 1.0000 - val_loss: 0.0500\n",
      "Epoch 347/500\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Accuracy: 0.9590 - loss: 0.08076\n",
      "Model Almost Perfect. Training Cancelled\n",
      "\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - Accuracy: 0.9638 - loss: 0.0738 - val_Accuracy: 1.0000 - val_loss: 0.0565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x164b1699bb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN A MODEL\n",
    "\n",
    "model.fit(x,y,epochs=500,verbose=1,callbacks=[mycallback()],validation_data=[x_test,y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model.predict(x_test)\n",
    "y_predicts = np.argmax(predicts,axis=1)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_predicts)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flower Actual</th>\n",
       "      <th>Flower Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iris Virginia</td>\n",
       "      <td>Iris Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Iris Versicolor</td>\n",
       "      <td>Iris Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Iris Setosa</td>\n",
       "      <td>Iris Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Flower Actual Flower Predicted\n",
       "0       Iris Setosa      Iris Setosa\n",
       "1     Iris Virginia    Iris Virginia\n",
       "2       Iris Setosa      Iris Setosa\n",
       "3   Iris Versicolor  Iris Versicolor\n",
       "4     Iris Virginia    Iris Virginia\n",
       "5     Iris Virginia    Iris Virginia\n",
       "6     Iris Virginia    Iris Virginia\n",
       "7       Iris Setosa      Iris Setosa\n",
       "8     Iris Virginia    Iris Virginia\n",
       "9       Iris Setosa      Iris Setosa\n",
       "10  Iris Versicolor  Iris Versicolor\n",
       "11      Iris Setosa      Iris Setosa\n",
       "12      Iris Setosa      Iris Setosa\n",
       "13      Iris Setosa      Iris Setosa\n",
       "14  Iris Versicolor  Iris Versicolor\n",
       "15    Iris Virginia    Iris Virginia\n",
       "16    Iris Virginia    Iris Virginia\n",
       "17  Iris Versicolor  Iris Versicolor\n",
       "18      Iris Setosa      Iris Setosa\n",
       "19  Iris Versicolor  Iris Versicolor\n",
       "20      Iris Setosa      Iris Setosa\n",
       "21  Iris Versicolor  Iris Versicolor\n",
       "22    Iris Virginia    Iris Virginia\n",
       "23  Iris Versicolor  Iris Versicolor\n",
       "24      Iris Setosa      Iris Setosa\n",
       "25    Iris Virginia    Iris Virginia\n",
       "26  Iris Versicolor  Iris Versicolor\n",
       "27  Iris Versicolor  Iris Versicolor\n",
       "28      Iris Setosa      Iris Setosa\n",
       "29      Iris Setosa      Iris Setosa"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO DATAFRAME\n",
    "result = pd.DataFrame(y_test)\n",
    "result['Flower Predicted'] = y_predicts\n",
    "\n",
    "result = result.rename({0 : 'Flower Actual'},axis=1)\n",
    "\n",
    "\n",
    "flower = {\n",
    "    0 : 'Iris Setosa',\n",
    "    1 : 'Iris Versicolor',\n",
    "    2 : 'Iris Virginia'\n",
    "}\n",
    "\n",
    "# CHANGE LABEL \n",
    "result['Flower Actual'] = result['Flower Actual'].map(flower)\n",
    "result['Flower Predicted'] = result['Flower Predicted'].map(flower)\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
